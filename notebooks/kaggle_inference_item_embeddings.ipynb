{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!git clone https://github.com/icedarold/through-pages.git\n",
                "%cd through-pages\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SOTA Recommendation Pipeline: From Raw Data to Submission\n",
                "\n",
                "This notebook runs the full pipeline:\n",
                "1. **Preprocess State**: Clean interactions and items.\n",
                "2. **Content Encoding (Phase 2)**: Multilingual embeddings.\n",
                "3. **Multi-Interest (Phase 1)**: Train Transformer to extract 6 interest vectors.\n",
                "4. **Feature Engineering (Phase 3)**: Generate rich features for 200 candidates.\n",
                "5. **Reranking & Submission (Phase 4)**: Select Top 20."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e5cbf1b5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install dependencies\n",
                "!pip install -q sentence-transformers pyarrow fastparquet tqdm lightgbm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "27813ba6",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Setup Directories (Paths updated for Kaggle Environment)\n",
                "import os\n",
                "OUT_DIR = '/kaggle/working/through-pages/experiments/data_v1'\n",
                "os.makedirs(OUT_DIR, exist_ok=True)\n",
                "os.makedirs('/kaggle/working/through-pages/experiments/models_v1', exist_ok=True)\n",
                "\n",
                "print(\"Using Kaggle Input datasets: /kaggle/input/though-pages\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "060a0a57",
            "metadata": {},
            "source": [
                "### Step 3: Global Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0dfb4258",
            "metadata": {},
            "outputs": [],
            "source": [
                "!python3 src/preprocess.py\n",
                "!python3 src/data/items.py\n",
                "!python3 src/data/sequences.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "92186985",
            "metadata": {},
            "source": [
                "### Step 4: Phase 2 - Item Content Embeddings\n",
                "Generates 768-D vectors for all books."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c1fc6082",
            "metadata": {},
            "outputs": [],
            "source": [
                "!python3 src/models/item_encoder.py --batch_size 128"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fc567523",
            "metadata": {},
            "source": [
                "### Step 5: Phase 1 - Multi-Interest Learning\n",
                "Training the User Encoder to understand multi-faceted interests."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "76652434",
            "metadata": {},
            "outputs": [],
            "source": [
                "!python3 src/data/enrich_items.py\n",
                "!python3 src/train.py --epochs 30 --batch-size 256\n",
                "!python3 src/inference_user.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2da67373",
            "metadata": {},
            "source": [
                "### Step 6: Phase 3 & 4 - SOTA Reranker\n",
                "Preparing the Training Data and Gradient Boosting model (LightGBM)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "36452281",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Create pairs for training reranker\n",
                "!python3 src/data/make_reranker_train_data.py\n",
                "\n",
                "# 2. Calculate features for Train pairs\n",
                "!python3 src/data/feature_factory.py --mode train\n",
                "\n",
                "# 3. Calculate features for Inference pairs (Candidates)\n",
                "!python3 src/data/feature_factory.py --mode infer\n",
                "\n",
                "# 4. Train LightGBM LambdaRank\n",
                "!python3 src/models/train_reranker.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4693a472",
            "metadata": {},
            "source": [
                "### Step 7: Final Submission Generation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d7216634",
            "metadata": {},
            "outputs": [],
            "source": [
                "!python3 src/submit.py --features $OUT_DIR/features_infer.parquet --output submission.csv\n",
                "\n",
                "import pandas as pd\n",
                "sub = pd.read_csv('submission.csv')\n",
                "print(\"Submission generated successfully!\")\n",
                "display(sub.head(20))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}