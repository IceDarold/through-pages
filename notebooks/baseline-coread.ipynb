{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Baseline: Co-Read CF\n",
    "\n",
    "Goal: build a simple baseline and produce `submission.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setup: imports and reproducibility\n",
    "# If needed:\n",
    "# pip install pandas numpy scipy tqdm\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "SUBMIT_DIR = \"submit\"\n",
    "\n",
    "users = pd.read_csv(os.path.join(DATA_DIR, \"users.csv\"))\n",
    "interactions = pd.read_csv(os.path.join(DATA_DIR, \"interactions.csv\"), parse_dates=[\"event_ts\"])\n",
    "editions = pd.read_csv(os.path.join(DATA_DIR, \"editions.csv\"))\n",
    "book_genres = pd.read_csv(os.path.join(DATA_DIR, \"book_genres.csv\"))\n",
    "\n",
    "targets = pd.read_csv(os.path.join(SUBMIT_DIR, \"targets.csv\"))\n",
    "candidates = pd.read_csv(os.path.join(SUBMIT_DIR, \"candidates.csv\"))\n",
    "\n",
    "print(\"users\", users.shape)\n",
    "print(\"interactions\", interactions.shape)\n",
    "print(\"editions\", editions.shape)\n",
    "print(\"book_genres\", book_genres.shape)\n",
    "print(\"targets\", targets.shape)\n",
    "print(\"candidates\", candidates.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID mappings"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_user_ids = pd.Index(pd.concat([users[\"user_id\"], interactions[\"user_id\"], targets[\"user_id\"]]).unique())\n",
    "all_edition_ids = pd.Index(pd.concat([editions[\"edition_id\"], interactions[\"edition_id\"], candidates[\"edition_id\"]]).unique())\n",
    "\n",
    "user2idx = {u: i for i, u in enumerate(all_user_ids)}\n",
    "item2idx = {it: i for i, it in enumerate(all_edition_ids)}\n",
    "idx2item = {i: it for it, i in item2idx.items()}\n",
    "\n",
    "n_users = len(all_user_ids)\n",
    "n_items = len(all_edition_ids)\n",
    "\n",
    "interactions[\"u\"] = interactions[\"user_id\"].map(user2idx).astype(np.int64)\n",
    "interactions[\"i\"] = interactions[\"edition_id\"].map(item2idx).astype(np.int64)\n",
    "\n",
    "print(\"n_users\", n_users, \"n_items\", n_items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction weights"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_weight(df: pd.DataFrame) -> np.ndarray:\n",
    "    w = np.zeros(len(df), dtype=np.float32)\n",
    "    is_wish = df[\"event_type\"] == 1\n",
    "    is_read = df[\"event_type\"] == 2\n",
    "\n",
    "    w[is_wish] = 1.0\n",
    "    w[is_read] = 3.0\n",
    "\n",
    "    r = df[\"rating\"].astype(\"float32\").fillna(0.0).clip(0.0, 5.0) / 5.0\n",
    "    w[is_read] += 0.2 * r[is_read].to_numpy()\n",
    "    return w\n",
    "\n",
    "interactions[\"w\"] = make_weight(interactions)\n",
    "interactions[[\"user_id\", \"edition_id\", \"event_type\", \"rating\", \"w\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional local time split (30 days)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "DO_LOCAL_SPLIT = True\n",
    "\n",
    "if DO_LOCAL_SPLIT:\n",
    "    interactions = interactions.sort_values([\"u\", \"event_ts\"])\n",
    "    max_ts = interactions.groupby(\"u\")[\"event_ts\"].transform(\"max\")\n",
    "    cutoff = max_ts - pd.Timedelta(days=30)\n",
    "\n",
    "    train_df = interactions[interactions[\"event_ts\"] < cutoff].copy()\n",
    "    val_df = interactions[interactions[\"event_ts\"] >= cutoff].copy()\n",
    "else:\n",
    "    train_df = interactions.copy()\n",
    "    val_df = None\n",
    "\n",
    "print(\"train events\", len(train_df), \"val events\", 0 if val_df is None else len(val_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local scorer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "ed2book = dict(zip(editions[\"edition_id\"].values, editions[\"book_id\"].values))\n",
    "bg = book_genres.groupby(\"book_id\")[\"genre_id\"].apply(lambda s: set(s.values)).to_dict()\n",
    "\n",
    "ed2genres = {}\n",
    "for ed in all_edition_ids:\n",
    "    b = ed2book.get(ed, None)\n",
    "    ed2genres[ed] = bg.get(b, set())\n",
    "\n",
    "def build_relevance(val_df):\n",
    "    rel = defaultdict(dict)\n",
    "    if val_df is None or len(val_df) == 0:\n",
    "        return rel\n",
    "    for (u, ed), grp in val_df.groupby([\"user_id\", \"edition_id\"]):\n",
    "        if (grp[\"event_type\"] == 2).any():\n",
    "            rel[u][ed] = 3\n",
    "        elif (grp[\"event_type\"] == 1).any():\n",
    "            rel[u][ed] = 1\n",
    "    return rel\n",
    "\n",
    "def ndcg_at_20(ranked_items, rel_u):\n",
    "    gains = []\n",
    "    for k, ed in enumerate(ranked_items, start=1):\n",
    "        r = rel_u.get(ed, 0)\n",
    "        gains.append(r / math.log2(k + 1))\n",
    "    dcg = sum(gains)\n",
    "\n",
    "    ideal_rels = sorted(rel_u.values(), reverse=True)[:20]\n",
    "    idcg = 0.0\n",
    "    for k, r in enumerate(ideal_rels, start=1):\n",
    "        idcg += r / math.log2(k + 1)\n",
    "    return 0.0 if idcg == 0 else dcg / idcg\n",
    "\n",
    "def jaccard_dist(a, b):\n",
    "    if not a and not b:\n",
    "        return 0.0\n",
    "    inter = len(a & b)\n",
    "    union = len(a | b)\n",
    "    return 1.0 - (inter / union if union else 0.0)\n",
    "\n",
    "def diversity_at_20(ranked_items, rel_u):\n",
    "    rel_mask = [rel_u.get(ed, 0) > 0 for ed in ranked_items]\n",
    "    rel_items = [ed for ed, m in zip(ranked_items, rel_mask) if m]\n",
    "\n",
    "    w = [1.0 / math.log2(k + 1) for k in range(1, 21)]\n",
    "\n",
    "    S = set()\n",
    "    num = 0.0\n",
    "    den = 0.0\n",
    "    for k, ed in enumerate(ranked_items, start=1):\n",
    "        g = ed2genres.get(ed, set())\n",
    "        if len(g) == 0:\n",
    "            den += w[k-1] * 0.0\n",
    "            continue\n",
    "        if rel_u.get(ed, 0) > 0:\n",
    "            new = len(g - S) / len(g)\n",
    "            num += w[k-1] * new\n",
    "            S |= g\n",
    "        den += w[k-1] * len(g)\n",
    "    coverage = 0.0 if den == 0 else num / den\n",
    "\n",
    "    if len(rel_items) < 2:\n",
    "        ild = 0.0\n",
    "    else:\n",
    "        dsum = 0.0\n",
    "        cnt = 0\n",
    "        for i in range(len(rel_items)):\n",
    "            for j in range(i + 1, len(rel_items)):\n",
    "                dsum += jaccard_dist(ed2genres.get(rel_items[i], set()), ed2genres.get(rel_items[j], set()))\n",
    "                cnt += 1\n",
    "        ild = dsum / cnt if cnt > 0 else 0.0\n",
    "\n",
    "    return 0.5 * coverage + 0.5 * ild\n",
    "\n",
    "def score_submission(pred_df, val_df):\n",
    "    rel = build_relevance(val_df)\n",
    "    users = pred_df[\"user_id\"].unique()\n",
    "\n",
    "    ndcgs = []\n",
    "    divs = []\n",
    "    for u in users:\n",
    "        ranked = pred_df[pred_df[\"user_id\"] == u].sort_values(\"rank\")[\"edition_id\"].tolist()\n",
    "        rel_u = rel.get(u, {})\n",
    "        ndcgs.append(ndcg_at_20(ranked, rel_u))\n",
    "        divs.append(diversity_at_20(ranked, rel_u))\n",
    "\n",
    "    ndcg = float(np.mean(ndcgs)) if ndcgs else 0.0\n",
    "    div = float(np.mean(divs)) if divs else 0.0\n",
    "    score = 0.7 * ndcg + 0.3 * div\n",
    "    return ndcg, div, score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build validation candidate pool (200 per user)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "item_pop = train_df.groupby(\"i\").size().sort_values(ascending=False)\n",
    "item_pop_rank = item_pop.index.to_numpy()\n",
    "\n",
    "user_items = train_df.groupby(\"u\")[\"i\"].apply(list).to_dict()\n",
    "item_users = train_df.groupby(\"i\")[\"u\"].apply(list).to_dict()\n",
    "\n",
    "ed2genres_idx = {item2idx[ed]: ed2genres.get(ed, set()) for ed in all_edition_ids if ed in item2idx}\n",
    "\n",
    "genre_to_items = {}\n",
    "for item_idx in range(n_items):\n",
    "    gset = ed2genres_idx.get(item_idx, set())\n",
    "    for g in gset:\n",
    "        genre_to_items.setdefault(g, []).append(item_idx)\n",
    "\n",
    "for g, items in genre_to_items.items():\n",
    "    items.sort(key=lambda x: item_pop.get(x, 0), reverse=True)\n",
    "\n",
    "def build_val_candidates(val_df, per_user=200, pop_k=200, genre_k=200, coread_k=200,\n",
    "                         max_seed_items=5, max_users_per_item=200, max_items_per_user=20):\n",
    "    val_users = val_df[\"user_id\"].unique()\n",
    "    val_pairs = val_df.groupby(\"user_id\")[\"edition_id\"].apply(set).to_dict()\n",
    "\n",
    "    rows = []\n",
    "    for u in tqdm(val_users, desc=\"build val candidates\"):\n",
    "        u_idx = user2idx[u]\n",
    "        train_items = set(user_items.get(u_idx, []))\n",
    "        positives = set(item2idx[ed] for ed in val_pairs.get(u, set()) if ed in item2idx)\n",
    "\n",
    "        cand = set(positives)\n",
    "\n",
    "        for it in item_pop_rank[:pop_k]:\n",
    "            if it not in train_items:\n",
    "                cand.add(it)\n",
    "            if len(cand) >= per_user:\n",
    "                break\n",
    "\n",
    "        gcount = Counter()\n",
    "        for it in list(train_items)[:200]:\n",
    "            for g in ed2genres_idx.get(it, set()):\n",
    "                gcount[g] += 1\n",
    "\n",
    "        top_genres = [g for g, _ in gcount.most_common(10)]\n",
    "        for g in top_genres:\n",
    "            for it in genre_to_items.get(g, [])[:genre_k]:\n",
    "                if it not in train_items:\n",
    "                    cand.add(it)\n",
    "                if len(cand) >= per_user:\n",
    "                    break\n",
    "            if len(cand) >= per_user:\n",
    "                break\n",
    "\n",
    "        seed_items = list(train_items)[:max_seed_items]\n",
    "        for it in seed_items:\n",
    "            users = item_users.get(it, [])\n",
    "            if len(users) > max_users_per_item:\n",
    "                users = rng.choice(users, size=max_users_per_item, replace=False)\n",
    "            for v in users:\n",
    "                v_items = user_items.get(v, [])[:max_items_per_user]\n",
    "                for it2 in v_items:\n",
    "                    if it2 not in train_items:\n",
    "                        cand.add(it2)\n",
    "                    if len(cand) >= per_user:\n",
    "                        break\n",
    "                if len(cand) >= per_user:\n",
    "                    break\n",
    "            if len(cand) >= per_user:\n",
    "                break\n",
    "\n",
    "        if len(cand) < per_user:\n",
    "            pool = [it for it in item_pop_rank if it not in train_items]\n",
    "            need = per_user - len(cand)\n",
    "            if need > 0:\n",
    "                extra = rng.choice(pool, size=min(need, len(pool)), replace=False)\n",
    "                cand.update(extra)\n",
    "\n",
    "        cand_list = list(cand)[:per_user]\n",
    "        for it in cand_list:\n",
    "            rows.append((u, idx2item[it]))\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\"user_id\", \"edition_id\"])\n",
    "\n",
    "if val_df is not None and len(val_df) > 0:\n",
    "    val_candidates = build_val_candidates(val_df, per_user=200)\n",
    "    print(val_candidates.head())\n",
    "    print(\"val candidates rows\", len(val_candidates))\n",
    "else:\n",
    "    val_candidates = None\n",
    "    print(\"val_df is empty; cannot build validation candidates.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diversity rerank helper"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def jaccard_dist(a: set, b: set) -> float:\n",
    "    if not a and not b:\n",
    "        return 0.0\n",
    "    inter = len(a & b)\n",
    "    union = len(a | b)\n",
    "    return 1.0 - (inter / union if union else 0.0)\n",
    "\n",
    "def rerank_diverse(df_user: pd.DataFrame, topk=20, lam=0.15, gamma=0.5):\n",
    "    items = df_user.sort_values(\"score\", ascending=False)[[\"edition_id\", \"score\"]].to_records(index=False)\n",
    "\n",
    "    chosen = []\n",
    "    chosen_genres = set()\n",
    "\n",
    "    for _ in range(topk):\n",
    "        best = None\n",
    "        best_val = -1e18\n",
    "\n",
    "        for ed, s in items:\n",
    "            if ed in chosen:\n",
    "                continue\n",
    "\n",
    "            g = ed2genres.get(ed, set())\n",
    "            if len(g) > 0:\n",
    "                new = len(g - chosen_genres) / len(g)\n",
    "            else:\n",
    "                new = 0.0\n",
    "\n",
    "            if not chosen:\n",
    "                ild = 0.0\n",
    "            else:\n",
    "                dsum = 0.0\n",
    "                for prev in chosen:\n",
    "                    dsum += jaccard_dist(g, ed2genres.get(prev, set()))\n",
    "                ild = dsum / len(chosen)\n",
    "\n",
    "            val = float(s) + lam * (new + gamma * ild)\n",
    "            if val > best_val:\n",
    "                best_val = val\n",
    "                best = ed\n",
    "\n",
    "        chosen.append(best)\n",
    "        chosen_genres |= ed2genres.get(best, set())\n",
    "\n",
    "    return chosen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline scoring"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# co-read score: sum of overlaps between candidate and user's seed items\n",
    "\n",
    "# item -> users set\n",
    "item_users = train_df.groupby(\"i\")[\"u\"].apply(lambda s: set(s.values)).to_dict()\n",
    "# user -> items list\n",
    "user_items = train_df.groupby(\"u\")[\"i\"].apply(list).to_dict()\n",
    "\n",
    "MAX_SEED_ITEMS = 5\n",
    "\n",
    "# preconvert to sets for speed\n",
    "item_users = {k: v for k, v in item_users.items()}\n",
    "\n",
    "\n",
    "def score_candidates(cand_df):\n",
    "    cand = cand_df.copy()\n",
    "    cand[\"u\"] = cand[\"user_id\"].map(user2idx).astype(np.int64)\n",
    "    cand[\"i\"] = cand[\"edition_id\"].map(item2idx).astype(np.int64)\n",
    "\n",
    "    scores = []\n",
    "    for u, it in zip(cand[\"u\"].values, cand[\"i\"].values):\n",
    "        seed_items = user_items.get(u, [])[:MAX_SEED_ITEMS]\n",
    "        if not seed_items:\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "        users_it = item_users.get(it, set())\n",
    "        s = 0.0\n",
    "        for s_it in seed_items:\n",
    "            users_s = item_users.get(s_it, set())\n",
    "            if not users_it or not users_s:\n",
    "                continue\n",
    "            # overlap size\n",
    "            s += len(users_it & users_s)\n",
    "        scores.append(s)\n",
    "\n",
    "    cand[\"score\"] = np.array(scores, dtype=np.float32)\n",
    "    return cand[[\"user_id\", \"edition_id\", \"score\"]]\n",
    "\n",
    "cand_scored = score_candidates(candidates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build submission"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_rows = []\n",
    "for u, grp in tqdm(cand_scored.groupby(\"user_id\"), total=cand_scored[\"user_id\"].nunique()):\n",
    "    chosen = rerank_diverse(grp, topk=20, lam=0.15, gamma=0.5)\n",
    "    for r, ed in enumerate(chosen, start=1):\n",
    "        pred_rows.append((u, ed, r))\n",
    "\n",
    "submission = pd.DataFrame(pred_rows, columns=[\"user_id\", \"edition_id\", \"rank\"])\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save submission"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "out_path = \"submission.csv\"\n",
    "submission.to_csv(out_path, index=False)\n",
    "print(\"saved\", out_path)\n",
    "\n",
    "ok_20 = submission.groupby(\"user_id\").size().eq(20).all()\n",
    "unique_ed = submission.groupby(\"user_id\")[\"edition_id\"].nunique().eq(20).all()\n",
    "unique_rank = submission.groupby(\"user_id\")[\"rank\"].nunique().eq(20).all()\n",
    "print(\"20 rows per user\", ok_20)\n",
    "print(\"unique edition_id\", unique_ed)\n",
    "print(\"unique rank\", unique_rank)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on validation candidates"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "if val_candidates is not None:\n",
    "    val_scored = score_candidates(val_candidates)\n",
    "\n",
    "    pred_rows = []\n",
    "    for u, grp in tqdm(val_scored.groupby(\"user_id\"), total=val_scored[\"user_id\"].nunique()):\n",
    "        chosen = rerank_diverse(grp, topk=20, lam=0.15, gamma=0.5)\n",
    "        for r, ed in enumerate(chosen, start=1):\n",
    "            pred_rows.append((u, ed, r))\n",
    "\n",
    "    val_submission = pd.DataFrame(pred_rows, columns=[\"user_id\", \"edition_id\", \"rank\"])\n",
    "\n",
    "    ndcg, div, score = score_submission(val_submission, val_df)\n",
    "    print(f\"local NDCG@20: {ndcg:.6f}\")\n",
    "    print(f\"local Diversity@20: {div:.6f}\")\n",
    "    print(f\"local Score: {score:.6f}\")\n",
    "else:\n",
    "    print(\"val_candidates is None; skip validation scoring.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}